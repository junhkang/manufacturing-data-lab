# 🔬 실습 시나리오: AWS Glue 기반 제조 품질 진단 파이프라인 자동화

## 🏭 배경

- 한 자동차 부품 공장에서는 **가스 사출 성형** 방식으로 부품을 대량 생산 중입니다.
- 제품의 품질은 내부 두께 균일성과 온도 분포에 민감하게 반응합니다.
- 센서를 통해 수집된 열화상 기반 온도 벡터 데이터는 S3에 저장되어 있으며, 기존에는 수동 분석으로 진행되었습니다.

## ❌ 기존 문제 상황

- 품질 분석은 **수동 Python 스크립트**를 통해 주기적으로 로컬 환경에서 실행되어야 했습니다.
- 품질 기준이 바뀌면 분석 기준 파일도 수작업으로 갱신해야 했습니다.
- 분석 결과는 각 팀이 따로 CSV를 내려받아 관리하면서 **버전 관리, 협업, 통합 통계 작성에 어려움**이 존재했습니다.
- 분석 결과를 쿼리하려면 로컬에서 결과 파일을 수집하고 열어보는 작업이 필요했습니다.

## ✅ 해결 방안

- AWS Glue Job을 통해 **센서 데이터 → 라벨링 → 평가 → 리포트 생성** 과정을 자동화합니다.
- 분석 기준(Rules)은 S3에 JSON으로 버전 관리하며 Glue Job이 자동으로 최신 파일을 선택합니다.
- 분석 결과는 S3에 저장되며, **AWS Athena를 통해 실시간 쿼리 가능**한 구조로 구성합니다.
- 이를 통해 **협업 부서가 언제든 결과를 쿼리하거나 시각화(예: QuickSight)할 수 있습니다.

---

## 🎯 실습 목표

- AWS Glue에서 PySpark 기반 데이터 파이프라인을 구성하는 방법을 익힌다.
- S3의 입력 데이터를 기준에 따라 자동 라벨링하고, NG 비율 등의 통계 정보를 계산한다.
- 분석 기준을 자동 선택하고, 결과를 S3에 저장 및 카탈로그 등록까지 수행한다.
- Athena를 통해 쿼리 가능한 구조로 파이프라인을 마무리한다.

---

## 🧪 실습 단계 요약

### 1. 데이터 준비 및 테이블 등록

- `left_data.csv` : 열화상 벡터 센서 데이터 (예: 1행 80열)
- `left_label.json` : 두께 기준 정보
- S3 `/input`에 업로드
- Glue Data Catalog에 테이블 등록 (또는 Glue Crawler 사용)

---

### 2. 품질 기준 로딩 및 라벨 생성

- S3 `/quality_rules/`에서 가장 최신 JSON 파일 로딩
- 두께 기준: `0.8mm < thickness < 1.5mm` → OK / 그 외 NG
- 기준 버전 정보도 함께 결과에 기록

---

### 3. 품질 진단 및 통계 분석

- 전체 데이터에 대해 라벨링 진행
- NG 비율, 평균 두께, 기준 외 범위 통계 추출
- NG 샘플은 별도로 추출하여 저장

---

### 4. 결과 저장 및 Athena 쿼리 연동

- 결과 CSV 및 JSON 저장 → `/output/` 디렉토리
- Glue Catalog 테이블 등록 또는 Parquet 변환하여 파티셔닝
- Athena에서 쿼리 가능 상태로 구성

---

## 💡 Glue 선택 이유

| 항목 | 기존 방식 | AWS Glue |
|------|-----------|-----------|
| 실행 환경 | 로컬, 수동 스크립트 | 서버리스, 자동화 |
| 기준 적용 | 수동 갱신 | 최신 기준 자동 선택 |
| 결과 활용 | CSV 다운로드 | Athena/QuickSight 연동 |
| 확장성 | 낮음 | 높은 확장성, 재사용 가능 |

---

> 본 실습은 제조 데이터 진단 파이프라인을 Glue 기반으로 재구성하여  
> **클라우드에서 실행되는 고가용성 ETL 자동화 프로세스**를 경험하는 데 목적이 있습니다.
